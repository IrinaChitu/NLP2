{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import *\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_DATASET_PATH = \"./data/dataset.csv\"\n",
    "DATASET_PATH = \"./data/\"\n",
    "# run `split_dataset` only once to create train/test/val \n",
    "# split_dataset(FULL_DATASET_PATH, DATASET_PATH, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe = pd.read_csv(os.path.join(DATASET_PATH, \"train.csv\"))\n",
    "val_dataframe = pd.read_csv(os.path.join(DATASET_PATH, \"val.csv\"))\n",
    "test_dataframe = pd.read_csv(os.path.join(DATASET_PATH, \"test.csv\"))\n",
    "\n",
    "for dataframe in [train_dataframe, val_dataframe, test_dataframe]:\n",
    "    dataframe[\"lyrics\"] = [normalization(song) for song in dataframe[\"lyrics\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'artists'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/School/Master I/NLP2/NLP2-Project/.env/lib/python3.8/site-packages/pandas/core/indexes/base.py:3361\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Documents/School/Master I/NLP2/NLP2-Project/.env/lib/python3.8/site-packages/pandas/_libs/index.pyx:76\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/School/Master I/NLP2/NLP2-Project/.env/lib/python3.8/site-packages/pandas/_libs/index.pyx:108\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'artists'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mtrain_dataframe\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43martists\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(tmp))\n",
      "File \u001b[0;32m~/Documents/School/Master I/NLP2/NLP2-Project/.env/lib/python3.8/site-packages/pandas/core/frame.py:3458\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3458\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3460\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Documents/School/Master I/NLP2/NLP2-Project/.env/lib/python3.8/site-packages/pandas/core/indexes/base.py:3363\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3362\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3363\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_scalar(key) \u001b[38;5;129;01mand\u001b[39;00m isna(key) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhasnans:\n\u001b[1;32m   3366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'artists'"
     ]
    }
   ],
   "source": [
    "tmp = set(train_dataframe[\"artist\"].tolist())\n",
    "print(len(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4530, 6) (1510, 6) (1510, 6)\n",
      "(4529, 6) (1510, 6) (1510, 6)\n"
     ]
    }
   ],
   "source": [
    "# Remove songs with less than 20 words after normalization\n",
    "print(train_dataframe.shape, val_dataframe.shape, test_dataframe.shape)\n",
    "for dataframe in [train_dataframe, val_dataframe, test_dataframe]:\n",
    "    indexes = []\n",
    "    for idx, row in enumerate(dataframe.to_numpy()):\n",
    "        if len(row[5]) <= 20:\n",
    "            indexes.append(idx)\n",
    "    dataframe.drop(index=indexes, inplace=True)\n",
    "print(train_dataframe.shape, val_dataframe.shape, test_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "tfidf_vect = TfidfVectorizer(min_df=5, max_df=0.8)\n",
    "\n",
    "tfidf_vect.fit(train_dataframe[\"lyrics\"])\n",
    "\n",
    "def transform_data(tfidf, dataframe):\n",
    "    features = tfidf_vect.transform(dataframe[\"lyrics\"])\n",
    "    return pd.DataFrame(features.todense(), columns=tfidf.get_feature_names_out())\n",
    "\n",
    "train_features = transform_data(tfidf_vect, train_dataframe)\n",
    "val_features = transform_data(tfidf_vect, val_dataframe)\n",
    "test_features = transform_data(tfidf_vect, test_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35%\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=5)\n",
    "parameters = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"n_estimators\": [100, 1000],\n",
    "    \"max_features\": [\"auto\", \"sqrt\"]\n",
    "}\n",
    "clf = GridSearchCV(clf, parameters, verbose=1)\n",
    "clf.fit(train_features, train_dataframe[\"artist\"])\n",
    "\n",
    "score = 0\n",
    "pred_labels = clf.predict(val_features)\n",
    "for i, name in enumerate(val_dataframe[\"artist\"]):\n",
    "    if pred_labels[i] == name:\n",
    "        score += 1\n",
    "print(f\"Validation acc: [{100.0 * score / len(pred_labels)}]\")\n",
    "\n",
    "score = 0\n",
    "pred_labels = clf.predict(test_features)\n",
    "for i, name in enumerate(test_dataframe[\"artist\"]):\n",
    "    if pred_labels[i] == name:\n",
    "        score += 1\n",
    "print(f\"Test acc:       [{100.0 * score / len(pred_labels)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Validation acc: [36.42384105960265]\n",
      "Test acc:       [33.17880794701987]\n"
     ]
    }
   ],
   "source": [
    "# 33%\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = SVC()\n",
    "parameters = {\n",
    "    \"kernel\": [\"rbf\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"],\n",
    "    \"C\": [1, 10]\n",
    "}\n",
    "clf = GridSearchCV(clf, parameters, verbose=1)\n",
    "clf.fit(train_features, train_dataframe[\"artist\"])\n",
    "\n",
    "score = 0\n",
    "pred_labels = clf.predict(val_features)\n",
    "for i, name in enumerate(val_dataframe[\"artist\"]):\n",
    "    if pred_labels[i] == name:\n",
    "        score += 1\n",
    "print(f\"Validation acc: [{100.0 * score / len(pred_labels)}]\")\n",
    "\n",
    "score = 0\n",
    "pred_labels = clf.predict(test_features)\n",
    "for i, name in enumerate(test_dataframe[\"artist\"]):\n",
    "    if pred_labels[i] == name:\n",
    "        score += 1\n",
    "print(f\"Test acc:       [{100.0 * score / len(pred_labels)}]\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1990ea6f36b583d2d095accfa7817870dd015584f5fcdbaa3efdeb4724026fdb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
