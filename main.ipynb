{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /home/eu3neuom/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocessing import *\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (4527, 6)\n",
      "test shape:  (1509, 6)\n",
      "val shape:   (1509, 6)\n"
     ]
    }
   ],
   "source": [
    "FULL_DATASET_PATH = \"./data/dataset.csv\"\n",
    "DATASET_PATH = \"./data/\"\n",
    "# run `split_dataset` only once to create train/test/val \n",
    "# split_dataset(FULL_DATASET_PATH, DATASET_PATH, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe = pd.read_csv(os.path.join(DATASET_PATH, \"train.csv\"))\n",
    "val_dataframe = pd.read_csv(os.path.join(DATASET_PATH, \"val.csv\"))\n",
    "test_dataframe = pd.read_csv(os.path.join(DATASET_PATH, \"test.csv\"))\n",
    "\n",
    "for dataframe in [train_dataframe, val_dataframe, test_dataframe]:\n",
    "    dataframe[\"lyrics\"] = [normalization(song) for song in dataframe[\"lyrics\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4530, 6) (1510, 6) (1510, 6)\n",
      "(4529, 6) (1510, 6) (1510, 6)\n"
     ]
    }
   ],
   "source": [
    "# Remove songs with less than 20 words after normalization\n",
    "print(train_dataframe.shape, val_dataframe.shape, test_dataframe.shape)\n",
    "for dataframe in [train_dataframe, val_dataframe, test_dataframe]:\n",
    "    indexes = []\n",
    "    for idx, row in enumerate(dataframe.to_numpy()):\n",
    "        if len(row[5]) <= 20:\n",
    "            indexes.append(idx)\n",
    "    dataframe.drop(index=indexes, inplace=True)\n",
    "print(train_dataframe.shape, val_dataframe.shape, test_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "tfidf_vect = TfidfVectorizer(min_df=5, max_df=0.8)\n",
    "\n",
    "tfidf_vect.fit(train_dataframe[\"lyrics\"])\n",
    "\n",
    "def transform_data(tfidf, dataframe):\n",
    "    features = tfidf_vect.transform(dataframe[\"lyrics\"])\n",
    "    return pd.DataFrame(features.todense(), columns=tfidf.get_feature_names_out())\n",
    "\n",
    "train_features = transform_data(tfidf_vect, train_dataframe)\n",
    "val_features = transform_data(tfidf_vect, val_dataframe)\n",
    "test_features = transform_data(tfidf_vect, test_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35%\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=5)\n",
    "parameters = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"n_estimators\": [100, 1000],\n",
    "    \"max_features\": [\"auto\", \"sqrt\"]\n",
    "}\n",
    "clf = GridSearchCV(clf, parameters, verbose=1)\n",
    "clf.fit(train_features, train_dataframe[\"artist\"])\n",
    "\n",
    "score = 0\n",
    "pred_labels = clf.predict(val_features)\n",
    "for i, name in enumerate(val_dataframe[\"artist\"]):\n",
    "    if pred_labels[i] == name:\n",
    "        score += 1\n",
    "print(f\"Validation acc: [{100.0 * score / len(pred_labels)}]\")\n",
    "\n",
    "score = 0\n",
    "pred_labels = clf.predict(test_features)\n",
    "for i, name in enumerate(test_dataframe[\"artist\"]):\n",
    "    if pred_labels[i] == name:\n",
    "        score += 1\n",
    "print(f\"Test acc:       [{100.0 * score / len(pred_labels)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Validation acc: [36.42384105960265]\n",
      "Test acc:       [33.17880794701987]\n"
     ]
    }
   ],
   "source": [
    "# 33%\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = SVC()\n",
    "parameters = {\n",
    "    \"kernel\": [\"rbf\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"],\n",
    "    \"C\": [1, 10]\n",
    "}\n",
    "clf = GridSearchCV(clf, parameters, verbose=1)\n",
    "clf.fit(train_features, train_dataframe[\"artist\"])\n",
    "\n",
    "score = 0\n",
    "pred_labels = clf.predict(val_features)\n",
    "for i, name in enumerate(val_dataframe[\"artist\"]):\n",
    "    if pred_labels[i] == name:\n",
    "        score += 1\n",
    "print(f\"Validation acc: [{100.0 * score / len(pred_labels)}]\")\n",
    "\n",
    "score = 0\n",
    "pred_labels = clf.predict(test_features)\n",
    "for i, name in enumerate(test_dataframe[\"artist\"]):\n",
    "    if pred_labels[i] == name:\n",
    "        score += 1\n",
    "print(f\"Test acc:       [{100.0 * score / len(pred_labels)}]\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1990ea6f36b583d2d095accfa7817870dd015584f5fcdbaa3efdeb4724026fdb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
